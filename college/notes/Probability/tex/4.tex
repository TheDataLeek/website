\documentclass[10pt]{article}

\input{./tex/header.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of document items - headers, title, toc, etc...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy}                                                       %  Establishes that the headers will be defined
\fancyhead[LE,LO]{Homework 4}                                  %  Adds header to left
\fancyhead[RE,RO]{Zoe Farmer}                                       %  Adds header to right
\cfoot{\mlptikz[size=0.25in, text=on, textposx=0, textposy=0, textvalue=\thepage, textscale=0.75in]{applejack}}
\lfoot{APPM 3570}
\rfoot{Kleiber}
\title{Homework 4}
\date{Kleiber}
\author{Zoe Farmer - 101446930}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of document items - headers, title, toc, etc...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

\begin{table}[!ht]
    \centering
    \scalebox{1.5}{%
    \begin{tabular}{|l|l|l|l||l|}
        \hline
        1 & 2 & 3 & 4 & T\\
        \hline
        & & & &\\
        \hline
    \end{tabular}
    }
\end{table}

\begin{easylist}[enumerate]
    @ Chapter 3, \#2, 6, 9, 13, 18, 32, 43, 49, 53, 60, 66, 67ac, 84

    @@ If two fair dice are rolled, what is the conditional probability that the first one lands on 6 given that the sum
    of the dice is $i$? Compute for all values of $i$ between 2 and 12.
    @@@ Let $E$ be the event that the first die lands on 6. Let $F_i$ be the event that the sum of the dice is $i$.
    Given this notation we are interested in the probability of
        \[ P(E|F_i), i = \{ 2, 3, \ldots, 11, 12 \} \]
    $P(F_i)$ is different for every $i$, as there are usually more than one way to create the sum. The probability is a
    sum of all the probabilities for the distinct ways.
        \[
            \begin{array}{cccc}
                \text{Sum} & \text{Ways} & & \text{Probability}\\
                2  & 1 & (1 + 1)                                    & \frac{1}{6} \cdot \frac{1}{6}\\
                3  & 2 & (1 + 2, 2 + 1)                             & 2 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                4  & 3 & (1 + 3, 3 + 1, 2 + 2)                      & 3 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                5  & 4 & (1 + 4, 4 + 1, 2 + 3, 3 + 2)               & 4 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                6  & 5 & (1 + 5, 5 + 1, 2 + 4, 4 + 2, 3 + 3)        & 5 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                7  & 6 & (1 + 6, 6 + 1, 2 + 5, 5 + 2, 3 + 4, 4 + 3) & 6 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                8  & 5 & (2 + 6, 6 + 2, 3 + 5, 5 + 3, 4 + 4)        & 5 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                9  & 4 & (3 + 6, 6 + 3, 4 + 5, 5 + 4)               & 4 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                10 & 3 & (4 + 6, 6 + 4, 5 + 5)                      & 3 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                11 & 2 & (5 + 6, 6 + 5)                             & 2 \left( \frac{1}{6} \cdot \frac{1}{6} \right)\\
                12 & 1 & (6 + 6)                                    & \frac{1}{6} \cdot \frac{1}{6}\\
            \end{array}
        \]
    Now that we have the probabilities of rolling for a sum, we can turn these to conditional probabilities. The first
    five probabilities are zero because there is no way to include zero when the sum of two dice has to be less than or
    equal zero. Probabilities are calculated using the conversion \[ P(E|F) = \frac{P(EF)}{P(F)} \]
        \[
            \begin{array}{ccc}
                \text{Statement} & \text{Probability} & \\
                P(E, F_2)        & 0                  & \\
                P(E, F_3)        & 0                  & \\
                P(E, F_4)        & 0                  & \\
                P(E, F_5)        & 0                  & \\
                P(E, F_6)        & 0                  & \\
                P(E, F_7)        & \frac{1/36}{1/6}   & 0.1666\\
                P(E, F_8)        & \frac{1/36}{5/36}  & 0.2\\
                P(E, F_9)        & \frac{1/36}{1/9}   & 0.25\\
                P(E, F_{10})     & \frac{1/36}{1/13}  & 0.3333\\
                P(E, F_{11})     & \frac{1/36}{1/18}  & 0.5\\
                P(E, F_{12})     & \frac{1/36}{1/36}  & 1\\
            \end{array}
        \]

    @@ Consider an urn containing 12 balls, of which 8 are white. A sample of size 4 is to be drawn with replacement
    (and without replacement). What is the conditional probability (in each case) that the first and third balls drawn
    will be white given that the sample drawn contains exactly 3 white balls?
    @@@ In the first case, each ball is replaced as it is drawn. Let $W_i$ be the event that the $i$th draw is a white
    ball, and $D_n$ be the event that $n$ drawn balls are white. Using these events, we're looking for the probability
    that the first and third balls are white, given that three white balls have been drawn.
        \[
            \begin{aligned}
                P(W_i) &=& 2/3\\
                P(D_n) &=& \binom{8}{n} \binom{4}{4 - n} \Big / \binom{12}{4}\\
                P(D_3) &=& \binom{8}{3} \binom{4}{1} \Big / \binom{12}{4} = \frac{224}{495} = 0.452525\\
                P(W_1 \cup W_3|D_3) &=& \frac{P((W_1 \cup W_3) \cap D_3)}{P(D_3)}\\
            \end{aligned}
        \]
    We can explicitly enumerate the possibilies for $W_1 \cup W_3$ as
        \[
            \begin{cases}
                \{ W, W, W, B \}\\
                \{ W, B, W, W \}
            \end{cases}
        \]
    Giving us the probability
        \[ P((W_1 \cup W_3) \cap D_3) = \frac{2}{\binom{12}{4}} \]
    Therefore this case has probability
        \[
            \begin{aligned}
                P(W_1 \cup W_3|D_3) &=& \frac{P((W_1 \cup W_3) \cap D_3)}{P(D_3)}\\
                                    &=& \frac{2}{\binom{12}{4}} \Big / \left( \frac{224}{495} \right)\\
                                    &=& \frac{1}{112} = \boxed{0.00892857}
            \end{aligned}
        \]
    @@@ In the second case, each ball is removed once it has been drawn. Let the same events apply from above, except
    now the odds of exactly three white balls being drawn is determined on a ball-by-ball basis.
        \[ P(D_3) = \binom{4}{3} {\left( \frac{2}{3} \right)}^3 \left( \frac{1}{3} \right) = \frac{32}{81} = 0.395062 \]
    We have the same set of possibilities as before, except now we need to again determine on a ball-by-ball basis,
    yielding
        \[ P((W_1 \cup W_3) \cap D_3) = {\left( \frac{2}{3} \right)}^3 \frac{1}{3} + {\left( \frac{2}{3} \right)}^3
        \frac{1}{3} = \frac{16}{81} = 0.197531 \]
    Therefore our final probability is
        \[ \frac{P((W_1 \cup W_3) \cap D_3)}{P(D_3)} = \frac{1}{2} = \boxed{0.5} \]

    @@ Consider 3 urns. Urn $A$ contains 2 white and 4 red balls, urn $B$ contains 8 white and 4 red balls, and urn $C$
    contains 1 white and 3 red balls. If 1 ball is selected from each urn, what is the probability that the ball chosen
    from urn $A$ was white given that exactly 2 white balls were selected?
    @@@ Let $E$ be the event that the ball chosen from urn $A$ was white. Let $F$ be the event that two white balls were
    chosen. In this case we're interested in $P(E|F)$.\newline

    First looking at $P(F)$ we can state each case individually. Let $A$, $B$, and $C$ correspond to the indices of the
    arrays, and we obtain our possibilities and probabilities.
        \[ \begin{aligned}
            \sum \left(
            \begin{cases}
                [ W, W, R ] \to \left( \frac{2}{6} \right)\left( \frac{8}{12} \right)\left( \frac{3}{4} \right) \to \frac{1}{6}\\
                [ W, R, W ] \to \left( \frac{2}{6} \right)\left( \frac{4}{12} \right)\left( \frac{1}{4} \right) \to \frac{1}{36}\\
                [ R, W, W ] \to \left( \frac{4}{6} \right)\left( \frac{8}{12} \right)\left( \frac{1}{4} \right) \to \frac{1}{9}\\
            \end{cases}\right)\\
            P(F) = \frac{1}{6} + \frac{1}{36} + \frac{1}{9} = \frac{11}{36}
        \end{aligned} \]
    We can now look at $P(EF)$, which consists of the cases solely where the first urn yields white. We can use our
    previously calculated probabilities to determine these cases.
        \[ P(EF) = \frac{1}{6} + \frac{1}{36} = \frac{7}{36} \]
    Now we can calculate $P(E|F)$ as
        \[ P(E|F) = \frac{P(EF)}{P(F)} = \frac{7/36}{11/36} = \frac{7}{11} = \boxed{0.636364} \]

    @@ Suppose that an ordinary deck of 52 cards (which contains 4 aces) is randomly divided into 4 hands of 13 cards
    each. We are interested in determining $p$, the probability that each hand has an ace. Let $E_i$ be the event that
    the ith hand has exactly one ace.  Determine $p = P(E_1 E_2 E_3 E_4 )$ by using the multiplication rule.
    @@@ Right off the bat we can restructure this problem to make it easier, and then solve for the quantities, finally
    reaching the solution.
        \[
            \begin{aligned}
                p =& P(E_1 E_2 E_3 E_4)\\
                  =& P(E_1) P(E_2 E_3 E_4|E_1)\\
                  =& P(E_1) P(E_2|E_1) P(E_3 E_4 | E_1 E_2)\\
                  =& P(E_1) P(E_2|E_1) P(E_3|E_1 E_2) P(E_4|E_1E_2E_3)\\
              P(E_1) =& \frac{\binom{4}{1} \binom{48}{12}}{\binom{52}{13}}\\
              P(E_2|E_1) =& \frac{\binom{3}{1} \binom{36}{12}}{\binom{39}{13}}\\
              P(E_3|E_1E_2) =& \frac{\binom{2}{1} \binom{24}{12}}{\binom{26}{13}}\\
              P(E_4|E_1E_2E_3) =& \frac{\binom{1}{1} \binom{12}{12}}{\binom{13}{13}}\\
              p =&
              \left( \frac{\binom{4}{1} \binom{48}{12}}{\binom{52}{13}} \right)
              \left( \frac{\binom{3}{1} \binom{36}{12}}{\binom{39}{13}} \right)
              \left( \frac{\binom{2}{1} \binom{24}{12}}{\binom{26}{13}} \right)
              \left( \frac{\binom{1}{1} \binom{12}{12}}{\binom{13}{13}} \right)\\
              =& \frac{2197}{20825} = \boxed{0.105498}
            \end{aligned}
        \]

    @@ A total of 46 percent of the voters in a certain city classify themselves as Independents, whereas 30 percent
    classify themselves as Liberals and 24 percent say that they are Conservatives. In a recent local election, 35
    percent of the Independents, 62 percent of the Liberals, and 58 percent of the Conservatives voted. A voter is
    chosen at random. Given that this person voted in the local election, what is the probability that he or she is
    @@@ an Independent?
    @@@@ We can rephrase this problem as one of conditional probability. Let $I$ be the event that the individual is
    independent, and similarily $L$ for liberals, and $C$ for conservatives. Also let $V$ be the event that the
    individual voted. We are given the individual probabilities. We are also given the probabilities that different
    groups voted.
        \[
            \begin{aligned}
                P(I) = 0.46\\
                P(L) = 0.30\\
                P(C) = 0.24\\
                P(V|I) = 0.35\\
                P(V|L) = 0.62\\
                P(V|C) = 0.58\\
            \end{aligned}
        \]

    Now we can look at independent voters. This problem is equivalently
        \[ P(I|V) = \frac{P(IV)}{P(V)} = \frac{P(I) P(V|I)}{P(V)} \]
    We now need to find $P(V)$.
        \[
            \begin{aligned}
                P(V) =& P(V|I)P(I) + P(L|I)P(L) + P(C|I)P(C)\\
                     =& 0.4862
            \end{aligned}
        \]
    Therefore we now can identify the probability that they are independent.
        \[ \frac{0.46 \cdot 0.35}{0.4862} = \boxed{0.331139} \]
    @@@ a Liberal?
    @@@@ Similarly
        \[ P(L|V) = \frac{P(LV)}{P(V)} = \frac{P(L) P(V|L)}{P(V)} = \boxed{0.382559} \]
    @@@ a Conservative?
    @@@@ Similarly
        \[ P(C|V) = \frac{P(CV)}{P(V)} = \frac{P(C) P(V|C)}{P(V)} = \boxed{0.286302} \]
    @@@ What fraction of voters participated in the local election?
    @@@@ This was determined above, $\boxed{0.4862}$.

    @@ A family has $j$ children with probability $p_j$, where $p_1 = 0.1$, $p_2 = 0.25$, $p_3 = 0.35$, $p_4 = 0.3$. A
    child from this family is randomly chosen. Given that this child is the eldest child in the family, find the
    conditional probability that the family has the following children. Redo for when the randomly selected child is the
    youngest child of the family.
    @@@ Only 1 child
    @@@@ Let $E$ be the event that the child is the eldest child in the family, and $C_i$ the event that the family has
    $i$ children. We are interested in $P(C_1|E)$. This
    can be restated as
        \[ P(C_1|E) = \frac{P(C_1E)}{P(E)} = \frac{P(C_1) P(E|C_1)}{P(E)} \]
    Now we need to find $P(E)$.
        \[ P(E) = \sum^4_{i=1} P(C_i) P(E|C_i) = 1 \cdot 0.1 + \frac{1}{2} \cdot 0.25 + \frac{1}{3} \cdot 0.35 +
        \frac{1}{4} \cdot 0.3 = 0.4167 \]
    Plugging $P(E)$ back in, we get
        \[ P(C_1|E) = \frac{P(C_1) P(E|C_1)}{P(E)} = \frac{0.1}{0.4167} = \boxed{0.24} \]
    Which is the same as if you use the youngest child.
    @@@ 4 children
    @@@@ We can use the same logic from before, except now we're interested in the case $C_4$.
        \[ P(C_4|E) = \frac{P(C_4) P(E|C_4)}{P(E)} = \frac{0.3 \cdot (1/4)}{0.4167} = \boxed{0.18} \]
    Which is the same as if you use the youngest child.

    @@ There are 3 coins in a box. One is a two-headed coin, another is a fair coin, and the third is a biased coin that
    comes up heads 75 percent of the time.  When one of the 3 coins is selected at random and flipped, it shows heads.
    What is the probability that it was the two-headed coin?
    @@@ Let $H$ be the event that the coin-flip results in heads, and $T$ be the event that we chose the two-headed coin
    when selecting the coin. All coins have an equal chance of being selected. We're interested in $P(T|H)$.
        \[ P(T|H) = \frac{P(TH)}{P(H)} = \frac{P(H|T) P(T)}{P(H)}\]
    Now we merely need to find the probability that we get heads, $P(H)$.
        \[ P(H) = \left( \frac{1}{3} \right) 1 +
                    \left( \frac{1}{3} \right) \left( \frac{1}{2} \right) +
                    \left( \frac{1}{3} \right) \left( \frac{3}{4} \right) =
                \frac{3}{4} \]
    Therefore our $P(T|H)$ is
        \[ P(T|H) = \frac{P(H|T) P(T)}{P(H)} = \frac{1/3}{3/4} = \boxed{0.444444} \]

    @@ Prostate cancer is the most common type of cancer found in males. As an indicator of whether a male has prostate
    cancer, doctors often perform a test that measures the level of the prostate-specific antigen (PSA) that is produced
    only by the prostate gland. Although PSA levels are indicative of cancer, the test is notoriously unreliable.
    Indeed, the probability that a noncancerous man will have an elevated PSA level is approximately 0.135, increasing
    to approximately 0.268 if the man does have cancer. If, on the basis of other factors, a physician is 70 percent
    certain that a male has prostate cancer, what is the conditional probability that he has the cancer given that
    @@@ the test indicated an elevated PSA level?
    @@@@ Similar to previous problems, let's start by establishing our events. Let $T$ be the event that the man has
    cancer, $F$ the event that he doesn't, $S$ the event that the man has elevated PSA levels, and $Q$ the event that he
    doesn't. We know some of these values.
        \[
            \begin{aligned}
                P(T) = 0.7\\
                P(F) = 0.3\\
                P(S|F) = 0.135\\
                P(S|T) = 0.268\\
            \end{aligned}
        \]
    We are interested in the probability that the test indicated an elevated level. In other words, $P(S)$.
        \[ P(S) = P(S|T)P(T) + P(S|F)(1 - P(T)) = 0.268 \cdot 0.7 + 0.135 ( 1 - 0.7) = \boxed{0.2281} \]
    @@@ the test did not indicate an elevated PSA level?
    @@@@ We are now interested in $P(Q)$, but since $Q = S^\prime$, we can easily calculate $P(Q)$ to be
        \[ P(Q) = 1 - P(S) = \boxed{0.7719} \]
    @@@ Repeat the preceding calculation, this time assuming that the physician initially believes that there is a 30
    percent chance that the man has prostate cancer.
    @@@@ We are know redefining $P(T) = 0.3, P(F) = 0.7$. This changes the previous calculation to be
        \[ P(Q) = 1 - \left( P(S|T)P(T) + P(S|F)(1 - P(T)) \right) = 1 - 0.1749 = \boxed{0.8251} \]

    @@ A parallel system functions whenever at least one of its components works. Consider a parallel system of $n$
    components, and suppose that each component works independently with probability 1/2.  Find the conditional
    probability that component 1 works given that the system is functioning.
    @@@ Let $F$ be the event that the system is functioning. Let $C_i$ be the event that the $i$th component is
    functional. We're interested in $P(C_1|F)$. We can determine some of our unknowns.
        \[ P(F) = 1 - { \left( \frac{1}{2} \right) }^n \]
    If this is the case, then we can calculate $P(C_1|F)$.
        \[ P(C_1|F) = \frac{P(C_1F)}{P(F)} = \frac{P(F|C_1)P(C_1)}{P(F)} \]
    We now have everything we need. We know that $P(F|C_1)$ is 1, because if \textit{any} component is functional, then
    the whole system is functional. We know that the individual probability of a distinct component working is
    $\frac{1}{2}$, and thereby we can solve for our single unknown.
        \[
            P(C_1|F) = \frac{P(F|C_1)P(C_1)}{P(F)} =
            \frac{1 \cdot \frac{1}{2}}
            {1-{\left(\frac{1}{2}\right)}^n} =
            \boxed{\frac{2^{n-1}}{2^n - 1}}
        \]

    @@ The color of a person's eyes is determined by a single pair of genes. If they are both blue-eyed genes, then the
    person will have blue eyes; if they are both brown-eyed genes, then the person will have brown eyes; and if one of
    them is a blue-eyed gene and the other a brown-eyed gene, then the person will have brown eyes. (Because of the
    latter fact, we say that the brown-eyed gene is dominant over the blue-eyed one.) A newborn child independently
    receives one eye gene from each of its parents, and the gene it receives from a parent is equally likely to be
    either of the two eye genes of that parent. Suppose that Smith and both of his parents have brown eyes, but Smith's
    sister has blue eyes.
    @@@ What is the probability that Smith possesses a blue-eyed gene?
    @@@@ We know that each gene has a 1/2 chance of being passed to the child, and we can explicitly enumerate the cases
    where Smith recieves the blue-eyed gene. We'll let $b$ indicate brown, and $B$ indicate blue.
        \[
            \begin{cases}
                \xcancel{[B, B]} \to (blue, blue)\\
                [ b, B ] \to (brown, blue)\\
                [ B, b ] \to (blue, brown)\\
                [ b, b ] \to (brown, brown)\\
            \end{cases}
        \]
    The probability of him getting the gene is 2/3.
    @@@ Suppose that Smith's wife has blue eyes. What is the probability that their first child will have blue eyes?
    @@@@ Again, we can explicitly enumerate the cases for the child's genes.
        \[
            \begin{cases}
                [ B, B ] \to (blue, blue)\\
                [ b, B ] \to (brown, blue)\\
                [ B, b ] \to (blue, brown)\\
                \xcancel{[ b, b ]} \to (brown, brown)\\
            \end{cases}
        \]
    The probability of their first child having blue eyes is 1/3.
    @@@ If their first child has brown eyes, what is the probability that their next child will also have brown eyes?
    @@@@ We can condition these event upon on another. Let $B_i$ be the event that the $i$th child will have brown eyes.
    The probability that any child has brown eyes is $3/4$.
        \[
            P(B_2|B_1) = \frac{P(B_1|B_2)P(B_2)}{P(B_1)} = \boxed{\frac{9}{16}}
        \]

    @@ The probability of the closing of the $i$th relay in the circuits shown in Figure 3.4 is given by $p_i$, $i = 1,
    2, 3, 4, 5$. If all relays function independently, what is the probability that a current flows between $A$ and $B$
    for the respective circuits?
    @@@ We can look at the two cases.
        \[ P(A\to B) = (p_1 p_2 + p_3 p_4) p_5 \]
    @@@ Again, we can look at the distinct cases.
        \[ (p_1p_4 + p_1p_5 + p_2p_5 + p_2p_4)p_3 + (p_1p_4 + p_2p_5)(1 - p_3).  \]

    @@ An engineering system consisting of $n$ components is said to be a $k$-out-of-$n$ system ($k \le n$) if the
    system functions if and only if at least $k$ of the $n$ components function. Suppose that all components function
    independently of each other.
    @@@ If the $i$th component functions with probability $P_i$, $i = 1, 2, 3, 4$, compute the probability that a
    2-out-of-4 system functions.
    @@@@ We can look at the cases separately.
        \[
            \begin{aligned}
                P(2-4) =& p_1 p_2 p_3 p_4 + (1 - p_1 )p_2 p_3 p_4 + p_1 (1 - p_2 )p_3 p_4 + p_1 p_2 (1 - p_3 )p_4 +\\
                &p_1 p_2 p_3 (1 - p_4 ) + (1 - p_1 )(1 - p_2 )p_3 p_4 + (1 - p_1 )p_2 (1 - p_3 )p_4 +\\
                &(1 - p_1 )p_2 p_3 (1 - p_4 ) + p_1 (1 - p_2 )(1 - p_3 )p_4 + p_1 (1 - p_2 )p_3 (1 - p_4 ) +\\
                &p_1 p_2 (1 - p_3 )(1 - p_4 )
            \end{aligned}
        \]
    @@ An urn contains 12 balls, of which 4 are white. Three players-$A$, $B$, and $C$-successively draw from the urn,
    $A$ first, then $B$, then $C$, then $A$, and so on. The winner is the first one to draw a white ball. Find the
    probability of winning for each player if
    @@@ each ball is replaced after it is drawn;
    @@@@ We need to look at this turn by turn. Each turn the player has the probability of winning of
    $\binom{4}{1}/\binom{12}{1}$, and let $W_i$ denote the event that turn $i$ is a winning turn. We can determine the
    probability of a certain player winning by conditioning the event on the outcome of the previous draws.
        \[
            \begin{aligned}
                P(A) =& P(A|W_1)P(W_1) + P(A|W_1^c W_2^c W_3^c)P(W_1^c W_2^c W_3^c )\\
                     =& P(W_1)P(A|W_1)+P(A|W_1^c W_2^c W_3^c )P (W_1^c )P (W_2^c )P (W_3^c )\\
                     =& P(W_1 )(1) + P (A)P (W_1^c )P (W_2^c )P (W_3^c )\\
                     =& \frac{9}{19} = \boxed{0.473684}\\
                P(B) =& \frac{6}{19} = \boxed{0.315789}\\
                P(C) =& \frac{4}{19} = \boxed{0.210526}\\
            \end{aligned}
        \]
    @@@ the balls that are withdrawn are not replaced.
    @@@@ In this case the chance of winning each turn is $\binom{4}{1}\Big /\binom{n}{1}$ where $n$ is the turn number,
    and we can express each person's chance of winning as a union of the situations in which they win. This can then be
    expanded and evaluated.
        \[
            \begin{aligned}
                P(A) =& W_1 \cup W_1^c W_2^c W_3^c W_4 \cup W_1^c W_2^c W_3^c W_4^c W_5^c W_6^c W_7\\
                     =& P(W_1) + P(W_1^c W_2^c W_3^c W_4) + P(W_1^c W_2^c W_3^c W_4^c W_5^c W_6^c W_7)\\
                     =& \frac{7}{15} = \boxed{0.466667}\\
                P(B) =& \frac{53}{165} = \boxed{0.321212}\\
                P(C) =& \frac{7}{33} = \boxed{0.212121}\\
            \end{aligned}
        \]

    @ Three cards are randomly selected, without replacement, from an ordinary deck of 52 playing cards.
    @@ Compute the probability that the first card selected is a spade.
    @@@ There are 13 spades in any given deck of cards, so the number of possibilities for the first draw (given the
    assumption that we are drawing a spade) is $\binom{13}{1}$.\newline

    There are a total of $\binom{52}{1}$ possibilities for the first card to be drawn. Therefore the probability of the
    first card drawn being a spade is
        \[ \binom{13}{1} \Big / \binom{52}{1} = \frac{1}{4} = \boxed{0.25} \]
    @@ Compute the probability that the second card selected is a spade.
    @@@ Using the same logic from before, we see that there are now $\binom{12}{1}$ possibilities for the second card
    being a spade with the assumption that our first card was a spade, and again our probability is calculated from the
    total number of combinations.
        \[ \binom{12}{1} \Big / \binom{51}{1} = \frac{4}{17} = \boxed{0.235294} \]
    @@ Compute the conditional probability that the first card selected is a spade, given that the second and third
    cards are spades. (Compare your answer in part (a) with your answer in part (c). Does it seem reasonable?)
    @@@ Let $S$ be the event that the second and third cards were spades, and $F$ be the event that the first card is a
    spade. We are interested in $P(F|S)$.
        \[ P(F|S) = \frac{P(FS)}{P(S)} = \frac{P(S|F) P(F)}{P(S)} \]
    Now we need to calculate some values.
        \[
            \begin{aligned}
                P(F) =& \frac{1}{4}\\
                P(S) =& \frac{\binom{13}{1}}{\binom{51}{1}} \cdot \frac{\binom{12}{1}}{\binom{50}{1}} = \frac{26}{425}\\
                P(S|F) =& \frac{\binom{12}{1}}{\binom{51}{1}} \cdot \frac{\binom{11}{1}}{\binom{50}{1}} = \frac{22}{425}\\
            \end{aligned}
        \]
    With these values it becomes apparent what the probability is.
        \[ P(F|S) = \frac{P(S|F) P(F)}{P(S)} = \frac{(22/425)(1/4)}{26/425} = \frac{11}{52} = \boxed{0.211538} \]
\end{easylist}

\end{document}
