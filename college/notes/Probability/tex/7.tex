\documentclass[10pt]{article}

\input{./tex/header.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of document items - headers, title, toc, etc...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy}                                                       %  Establishes that the headers will be defined
\fancyhead[LE,LO]{Homework 7}                                  %  Adds header to left
\fancyhead[RE,RO]{Zoe Farmer}                                       %  Adds header to right
\cfoot{\mlptikz[size=0.25in, text=on, textposx=0, textposy=0, textvalue=\thepage, textscale=0.75in]{applejack}}
\lfoot{APPM 3570}
\rfoot{Kleiber}
\title{Homework 7}
\date{Kleiber}
\author{Zoe Farmer - 101446930}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beginning of document items - headers, title, toc, etc...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

\begin{table}[!ht]
    \centering
    \scalebox{1.5}{%
    \begin{tabular}{|l|l|l|l||l|}
        \hline
        1 & 2 & 3 & 4 & T\\
        \hline
        & & & &\\
        \hline
    \end{tabular}
    }
\end{table}

\begin{easylist}[enumerate]
    \ListProperties(Hide1=50, Space1=1cm)
    @ \textit{Chapter 4, \#53 --} Approximately 80,000 marriages took place in the state of New York last year. Estimate
    the probability that, for at least one of these couples, (State your assumptions)
    @@ both partners were born on April 30.
    @@@ Assuming we have an even distribution of births across months of the year, and assuming that marriages are
    random, we see that the chance of being born on April 30 is 1/365. The chance that both have this birthday is

    \[
        \frac{1}{365} \cdot \frac{1}{365} = \frac{1}{133225} = \boxed{7.5061 \times 10^{-6}}
    \]

    @@ both partners celebrated their birthday on the same day of the year.
    @@@ Now we have to have the first pick the day (365 choose 1), and then the likelihood of the second person having
    the same day (1/365), and then divide by the total number of possibilities.

    \[ \binom{365}{1} \cdot \frac{1}{365} \Big / \binom{365}{1}^2 = \frac{1}{133225} = \boxed{7.5061 \times 10^{-6}} \]

    @ \textit{Chapter 4, \#57 --} Suppose that the number of accidents occurring on a highway each day is a Poisson
    random variable with parameter $\lambda = 3$.
    @@ Find the probability that 3 or more accidents occur today.
    @@@ To find this we can use the cdf of Pois(3) and get $\boxed{0.57681}$.
    @@ Repeat part (a) under the assumption that at least 1 accident occurs today.
    @@@ Again we can use the cdf of Pois(3) and get $\boxed{0.950213}$.

    @ \textit{Chapter 4, \#60 --} The number of times that a person contracts a cold in a given year is a Poisson random
    variable with parameter $\lambda = 5$. Suppose that a new wonder drug (based on large quantities of vitamin C) has
    just been marketed that reduces the Poisson parameter to $\lambda = 3$ for 75 percent of the population. For the
    other 25 percent of the population, the drug has no appreciable effect on colds. If an individual tries the drug for
    a year and has 2 colds in that time, how likely is it that the drug is beneficial for him or her?
    @@ Assuming that the chance that the drug affects you is random, we can determine the odds that the individual is
    affected by setting this up as a conditional probability question. Let $A$ be the event that it affects him, and
    $B_n$ be the event that he gets $n = 2$ colds in a year.

    \[
        P(A|B_2) = \frac{P(AB_2)}{P(B_2)} =
        \frac{P(B_2|A)P(A)}{P(B_2)} =
        \frac{P(B_2|A)P(A)}{P(B_2 | A)P(A) + P(B_2|A^c)P(A^c)} =
        \boxed{0.888644}
    \]

    @ \textit{Chapter 4, \#75 --} A fair coin is continually flipped until heads appears for the 10th time. Let $X$
    denote the number of tails that occur. Compute the probability mass function of $X$.
    @@ We can represent this situation as a negative binomial distribution with $r = 10$ and $p=0.5$ if we let the event
    that a heads appear be called a ``failure'' and a tails a ``success''. Therefore the probability mass function is

    \[
        p(k;r,p) =
        \begin{cases}
            \binom{k + r - 1}{k} \cdot {(1-p)}^r p^k\\
            0
        \end{cases} =
        \begin{cases}
            \binom{k + 9}{k} \cdot 0.5^{10k} &\to k \in \{0, 1, 2, \ldots\}\\
            0 &\to Otherwise
        \end{cases}
    \]

    @ \textit{Chapter 4, Theoretical Exercise \#7 --} Let $X$ be a random variable having expected value $\mu$ and
    variance $\sigma^2$. Find the expected value and variance of

    \[ Y = \frac{X - \mu}{\sigma} \]

    @@ This is the same as normalizing the curve to the normal distribution, meaning that the mean remains the same as
    well as the variance. $Y$ in essence is now equal to a normal distribution with $\mu=\mu$ and $\sigma=\sigma$, or
    a normal distribution with equivalent mean and standard deviation as the original distribution.

    @ \textit{Chapter 4, Theoretical Exercise \#27 --} If $X$ is a geometric random variable, show analytically that

    \[ P\{X = n + k|X > n\} = P\{X=k\} \]

    Using the interpretation of a geometric random variable, give a verbal argument as to why the preceding equation is
    true.
    @@@ If $X$ is a geometric random variable, this means that the pmf and cdf are

    \[
        P(k;p) =
        \begin{cases}
            {(1-p)}^{k-1}p &\to k \in \{0, 1, 2, 3, \ldots\}\\
            0 &\to Otherwise
        \end{cases}
        \qquad
        F(k;p) =
        \begin{cases}
            1-{(1-p)}^k &\to k \in \{0, 1, 2, 3, \ldots\}\\
            0 &\to Otherwise
        \end{cases}
    \]

    Therefore we see that we're interested in $P(k+n;p)$ given that $X$ is greater than $n$.

    \[
        \begin{aligned}
            P\{X = n + k|X > n\} &=&  P\{X=k\}\\
            P\{X = n + k|X > n\} &=& {(1-p)}^{k-1}p\\
            \text{We can manipulate one side}\\
            P\{X > n\} = \sum_{i = n+1}^\infty p(i) &=& \sum_{i = n+1}^\infty {(1-p)}^{i - 1}p\\
            &=& p {(1-p)}^n \sum_{i = 0}^\infty {(1-p)}^i = \frac{p {(1-p)}^n}{1-(1-p)}\\
            &=& (1-p)^n\\
        \end{aligned}
    \]

    Now that we have that taken care of, we can use the definition of conditional probability to find the answer.

    \[
        \begin{aligned}
            P\{X = n + k|X > n\} &=&  \frac{P\{X=n+k\}}{P\{X > n\}}\\
            &=& \frac{{(1-p)}^{(n+k-1)}p}{{(1-p)}^n}\\
            &=& {(1-p)}^{(k-1)}p\\
            &=& P(X=k)_\blacksquare\\
        \end{aligned}
    \]

    @ \textit{Chapter 5, \#3 --} Consider the function

    \[
        f(x) =
        \begin{cases}
            C(2x - x^3) &\to 0 < x < \frac{5}{2}\\
            0 &\to Otherwise
        \end{cases}
    \]

    Could $f$ be a probability density function? If so, determine $C$. Repeat if $f(x)$ were given by

    \[
        f(x) =
        \begin{cases}
            C(2x - x^2) &\to 0 < x < \frac{5}{2}\\
            0 &\to Otherwise
        \end{cases}
    \]
    @@ Yes, $f(x)$ could be a probability density function, but in order for it to work $c$ \textit{must} equal
    $-(64/225)$. This is determined by simply solving the following equation

    \[
        \int^\frac{5}{2}_0 c 2x - x^3) \, dx = 1
    \]

    If we had the other equation, then $c$ would need to be $(24/25)$.

    @ \textit{Chapter 5, \#4 --} The probability density function of $X$, the lifetime of a certain type of electronic
    device (measured in hours), is given by

    \[
        f(x) =
        \begin{cases}
            \frac{10}{x^2} &\to x > 10\\
            0 &\to x \le 10
        \end{cases}
    \]

    @@ Find $P\{X > 20\}$.
    @@@ This can also be expressed as

    \[ P(X > 20) = 1 - P(X \le 20) = \int^{20}_{10} f(x) \, dx = \boxed{0.5} \]

    @@ What is the cumulative distribution function of $X$?
    @@@

    \[
        F(x) = \int^x_{-\infty} f(x) \, dx
    \]

    @@ What is the probability that, of 6 such types of devices, at least 3 will function for at least 15 hours? What
    assumptions are you making?
    @@@ The probability of any device lasting for at least 15 hours is

    \[ \int^\infty_15 \frac{10}{x^2} \, dx = \frac{2}{3} \]

    Now we can use this to determine the odds of at least 6 surviving. Let $A$ be the probability of a survivor, and $B$
    similarly indicate a failure.

    \[ \binom{6}{3}A^3B^3 + \binom{6}{2}A^4B^2 + \binom{6}{1} A^5B^1 + A^6 = \frac{656}{729} = \boxed{0.899863} \]

    @ The expected number of typographical errors on a page of a certain magazine is 0.2.
    @@  What is the probability that the next page you read contains no errors?
    @@@ We can model this as a Poisson Distribution with $\lambda = 0.2$

    \[
        p(k;0.2) = \frac{0.2^k e^{-0.2}}{k!}
    \]

    And see that the probability that the number or errors is zero is $\boxed{0.818731}$.
    @@ What is the probability that the next page you read contains 2 or more errors?
    @@@ This is the same as one minus the cdf $F(k)$ with $k=1$ which is $\boxed{0.0175231}$.
    @@ In a ten page article, what is the probability that there is a total of no more than 2 errors?
    @@@ This is the sum of independent Poisson random variables.

    \[ X = \sum_{i=1}^{10} \left( X_i \to Poisson\left(\lambda = \sum_{i=1}^{10} \lambda_i = 10(0.2) = 2\right)\right) \]

    And therefore

    \[ P(X=x) = \frac{2^x e^{-2}}{x!} \]

    So

    \[
        P(X \ge 2) = 1 - P(X=0) - P(X=1) = \boxed{0.593}
    \]

    @@ What assumptions are you making in this problem?
    @@@ This is mainly assuming that every page has equal likelihood of having errors on it.

    @ Grasshoppers are distributed at random in a large field according to a Poisson distribution with parameter
    $\lambda = 2$ per square yard. How large should the radius $R$ of a circular sampling region be taken so that the
    probability of finding at least one in the region equals 0.99?
    @@ The area of a circle with radius $R$ is $\pi R^2$, and the chance of finding at least one in in a square yard is
    $\boxed{0.864665}$. Therefore if we multiply our radius by $\boxed{0.99/0.864665}$ then our chance is 0.99.

    @ The number of eggs laid on a tree leaf by an insect of a certain type is a Poisson random variable with parameter
    $\lambda$. However, such a random variable can only be observed if it is positive, since if it is 0, then we cannot
    know that such an insect was on the leaf. If we let $Y$ denote the observed number of eggs, then $P\{Y = i\} = P\{X
    = i |X > 0\}$ where $X$ is Poisson with parameter $\lambda$. Find $E[Y]$.
    @@ Similar to our previous problem, we can look at these events independently. We know that $P(X > 0)=1-P(X =
    0)=e^{-\lambda}$ and $P(X=k) = (\lambda^k e^{-\lambda})/(k!)$.

    \[
        \begin{aligned}
            E(X=i|X>0) &=& \sum_{x \in X} xP(X=x|X>0)\\
            &=& \sum_{x \in X} x\frac{P(X=x,X>0)}{P(X>0)}\\
            &=& \frac{1}{P(X>0)} \sum_{x \in X} xP(X=x,X>0)\\
            &=& \frac{1}{P(X>0)} E(X>0|X=i) P(X=i)\\
            &=& e^{-\lambda}
        \end{aligned}
    \]
\end{easylist}

\end{document}
