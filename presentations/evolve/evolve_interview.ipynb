{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn\n",
    "import datetime as dt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import heapq\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "import stemming\n",
    "from stemming import porter2\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import scipy\n",
    "import scipy.interpolate as sc_int\n",
    "import scipy.sparse as sc_sp\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from time import time\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evolve Interview Project\n",
    "\n",
    "## Zoë Farmer\n",
    "\n",
    "<img src=\"https://images.fineartamerica.com/images-medium-large-5/boston-back-bay-skyline-at-night-color-panorama-jon-holiday.jpg\" style=\"width: 100%;\" />\n",
    "\n",
    "*Press the space-bar to proceed to the next slide. [See here for a brief tutorial](http://lab.hakim.se/reveal-js/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Who am I?\n",
    "\n",
    "* My name is Zoë Farmer\n",
    "* Recent CU graduate with a BS in Applied Math and a CS Minor\n",
    "* Co-coordinator of the Boulder Python Meetup\n",
    "* Big fan of open source software\n",
    "* http://www.dataleek.io\n",
    "* [@thedataleek](http://www.twitter.com/thedataleek)\n",
    "* [git(hub|lab).com/thedataleek](http://github.com/thedataleek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## General Tooling Overview\n",
    "\n",
    "* Everything is in Python3.6\n",
    "* I use `jupyter`, `pandas`, `numpy`, `matplotlib`, `scikit-learn`, `nltk`, and `scipy`.\n",
    "* Some code has been skipped for brevity. See [this link](http://www.gitlab.com/thedataleek/evolve_interview) for full code.\n",
    "* Development performed with Jupyter Notebook, this notebook is available at the above link.\n",
    "* Presentation powered by Reveal.js\n",
    "\n",
    "<div>\n",
    "    <div style=\"display: inline-block; width: 16%;\"><img src=\"./evolve_interview/jupyter.svg\"/></div>\n",
    "    <div style=\"display: inline-block; width: 20%;\"><img src=\"./evolve_interview/pandas.png\"/></div>\n",
    "    <div style=\"display: inline-block; width: 12%;\"><img src=\"./evolve_interview/numpy.jpg\"/></div>\n",
    "    <div style=\"display: inline-block; width: 18%;\"><img src=\"./evolve_interview/matplotlib.svg\"/></div>\n",
    "    <div style=\"display: inline-block; width: 12%;\"><img src=\"./evolve_interview/sklearn.png\"/></div>\n",
    "    <div style=\"display: inline-block; width: 8%;\"><img src=\"./evolve_interview/scipy.png\"/></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is it?\n",
    "\n",
    "A year of data about Boston scraped from AirBnB that contains 2 datasets\n",
    "\n",
    "* listing details\n",
    "* calendar information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (1) Listings - details about locations\n",
    "\n",
    "Our first dataset is a large number of listings and associated descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_data = pd.read_csv('./ListingsAirbnbScrapeExam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3585"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id, name, summary, space, description, experiences_offered, neighborhood_overview, notes, transit, access, interaction, house_rules, host_name, host_since, host_location, host_about, host_response_time, host_response_rate, host_acceptance_rate, host_is_superhost, host_neighbourhood, host_listings_count, host_total_listings_count, host_verifications, host_has_profile_pic, host_identity_verified, street, neighbourhood_cleansed, city, state, zipcode, market, smart_location, country_code, country, latitude, longitude, is_location_exact, property_type, room_type, accommodates, bathrooms, bedrooms, beds, bed_type, amenities, square_feet, price, weekly_price, monthly_price, security_deposit, cleaning_fee, guests_included, extra_people, minimum_nights, maximum_nights, calendar_updated, has_availability, availability_30, availability_60, availability_90, availability_365, calendar_last_scraped, number_of_reviews, first_review, last_review, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, requires_license, license, jurisdiction_names, instant_bookable, cancellation_policy, require_guest_profile_picture, require_guest_phone_verification, calculated_host_listings_count, reviews_per_month'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(listing_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (2) Calendar Data - location occupancy by date\n",
    "\n",
    "Our second dataset is a set of listings by date, occupancy, and price.\n",
    "\n",
    "* We want to parse these fields\n",
    "    * datestrings to be formatted as python `datetime` objects\n",
    "    * price field to be floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "price_re = '^ *\\$([0-9]+\\.[0-9]{2}) *$'\n",
    "def price_converter(s):\n",
    "    match = re.match(price_re, s)\n",
    "    if match:\n",
    "        return float(match[1])\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_data = pd.read_csv(\n",
    "    './CalendarAirbnbScrapeExam.csv',\n",
    "    converters={\n",
    "        'available': lambda x: True if x == 'f' else False,\n",
    "        'price': price_converter\n",
    "    }\n",
    ")\n",
    "calendar_data['filled'] = ~calendar_data['available']\n",
    "calendar_data['date'] = pd.to_datetime(calendar_data['date'],\n",
    "                                       infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "      <th>filled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12147973</td>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id       date  available  price  filled\n",
       "0    12147973 2017-09-05       True    NaN   False"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dataset Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to combine datasets\n",
    "\n",
    "* Let's calculate the number of nights occupied per listing and add to the listing data.\n",
    "* Average/standard deviation price per night\n",
    "\n",
    "But let's first make sure the datasets overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Listing Keys: 3585\n",
      "# Calendar Keys: 2872\n",
      "# Difference: 713\n"
     ]
    }
   ],
   "source": [
    "listing_keys = set(listing_data.id)\n",
    "calendar_keys = set(calendar_data.listing_id)\n",
    "difference = listing_keys.difference(calendar_keys)\n",
    "print(f'# Listing Keys: {len(listing_keys)}')\n",
    "print(f'# Calendar Keys: {len(calendar_keys)}')\n",
    "print(f'# Difference: {len(difference)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They don't, in fact we're missing information on about 700 listings.\n",
    "\n",
    "For our `num_filled` column let's establish the assumption that a `NaN` value stands for \"unknown\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Groupby\n",
    "\n",
    "We can simply `sum()` our `available` and `filled` boolean fields. This will give us a total number of nights occupied (or available).\n",
    "\n",
    "Note, in the final aggregated sum these two fields sum to 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fill_dates = calendar_data\\\n",
    "    .groupby('listing_id')[['available', 'filled', 'price']]\\\n",
    "    .agg({\n",
    "        'available': 'sum',\n",
    "        'filled': 'sum',\n",
    "        'price': ['mean', 'std']\n",
    "    })\n",
    "fill_dates['listing_id'] = fill_dates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>available</th>\n",
       "      <th>filled</th>\n",
       "      <th colspan=\"2\" halign=\"left\">price</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>21.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>147.267442</td>\n",
       "      <td>17.043196</td>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>41.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>197.407407</td>\n",
       "      <td>17.553300</td>\n",
       "      <td>6695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6976</th>\n",
       "      <td>46.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>117.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>1.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           available filled       price            listing_id\n",
       "                 sum    sum        mean        std           \n",
       "listing_id                                                   \n",
       "5506            21.0  344.0  147.267442  17.043196       5506\n",
       "6695            41.0  324.0  197.407407  17.553300       6695\n",
       "6976            46.0  319.0   65.000000   0.000000       6976\n",
       "8792           117.0  248.0  154.000000   0.000000       8792\n",
       "9273             1.0  364.0  225.000000   0.000000       9273"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Left Join\n",
    "\n",
    "Now we merge with our original dataset using a left join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "combined_data = listing_data.merge(\n",
    "    fill_dates,\n",
    "    how='left',\n",
    "    left_on='id',\n",
    "    right_on='listing_id'\n",
    ")\n",
    "combined_data.rename(\n",
    "    columns={\n",
    "        ('available', 'sum'): 'available',\n",
    "        ('filled', 'sum'): 'filled',\n",
    "        ('price', 'mean'): 'avg_price',\n",
    "        ('price', 'std'): 'std_price'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make sure that merge worked the way we want it to\n",
    "for key in listing_data.id:\n",
    "    combined_val = combined_data[combined_data.id == key][['available']].values\n",
    "    fill_val = fill_dates[fill_dates.listing_id == key][['available']].values\n",
    "    try:\n",
    "        assert combined_val == fill_val\n",
    "    except AssertionError:\n",
    "        if np.isnan(combined_val[0, 0]) and len(fill_val) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            print(key, combined_val, fill_val)\n",
    "            raise\n",
    "for key in difference:\n",
    "    assert np.isnan(combined_data[combined_data.id == key][['available']].values[0, 0])\n",
    "    assert len(fill_dates[fill_dates.listing_id == key]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>available</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>std_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12147973</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>365.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3075044</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>6.0</td>\n",
       "      <td>67.813370</td>\n",
       "      <td>4.502791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6976</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>46.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436513</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>267.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7651065</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>31.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12386020</td>\n",
       "      <td>Private Bedroom + Great Coffee</td>\n",
       "      <td>307.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5706985</td>\n",
       "      <td>New Lrg Studio apt 15 min to Boston</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.755814</td>\n",
       "      <td>18.403439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2843445</td>\n",
       "      <td>\"Tranquility\" on \"Top of the Hill\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>753446</td>\n",
       "      <td>6 miles away from downtown Boston!</td>\n",
       "      <td>18.0</td>\n",
       "      <td>59.363112</td>\n",
       "      <td>3.629618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>849408</td>\n",
       "      <td>Perfect &amp; Practical Boston Rental</td>\n",
       "      <td>258.0</td>\n",
       "      <td>252.925234</td>\n",
       "      <td>31.012992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           name  available  \\\n",
       "0  12147973                     Sunny Bungalow in the City      365.0   \n",
       "1   3075044              Charming room in pet friendly apt        6.0   \n",
       "2      6976               Mexican Folk Art Haven in Boston       46.0   \n",
       "3   1436513  Spacious Sunny Bedroom Suite in Historic Home      267.0   \n",
       "4   7651065                            Come Home to Boston       31.0   \n",
       "5  12386020                 Private Bedroom + Great Coffee      307.0   \n",
       "6   5706985            New Lrg Studio apt 15 min to Boston       21.0   \n",
       "7   2843445             \"Tranquility\" on \"Top of the Hill\"        0.0   \n",
       "8    753446             6 miles away from downtown Boston!       18.0   \n",
       "9    849408              Perfect & Practical Boston Rental      258.0   \n",
       "\n",
       "    avg_price  std_price  \n",
       "0         NaN        NaN  \n",
       "1   67.813370   4.502791  \n",
       "2   65.000000   0.000000  \n",
       "3   75.000000   0.000000  \n",
       "4   79.000000   0.000000  \n",
       "5   75.000000   0.000000  \n",
       "6  111.755814  18.403439  \n",
       "7   75.000000   0.000000  \n",
       "8   59.363112   3.629618  \n",
       "9  252.925234  31.012992  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[['id', 'name', 'available', 'avg_price', 'std_price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Neighborhood Statistics\n",
    "\n",
    "Now that we've added those columns to the listing data, we can start to get neighborhood-specific statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "valid_combined = combined_data[~combined_data['available'].isnull()]\n",
    "neighborhood_stats = valid_combined\\\n",
    "    .groupby('neighbourhood_cleansed')\\\n",
    "    .agg({\n",
    "        'avg_price': 'mean',\n",
    "        'std_price': 'mean'\n",
    "    }\n",
    ")\n",
    "neighborhood_stats.sort_values('avg_price', inplace=True)\n",
    "neighborhood_stats.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Neighborhood Price and Standard Deviation')\n",
    "plt.xlabel('Neighborhood')\n",
    "plt.ylabel('Cost (Dollars)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./evolve_interview/neighborhood_stats.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./evolve_interview/neighborhood_stats.png\" style=\"width: 100%; height: 50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seasonal Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have a year of data, let's examine how seasons effect occupancy.\n",
    "\n",
    "We can take a naive approach and simply `groupby` each date and plot the number of dates filled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "calendar_data.groupby('date')[['filled']].sum().plot(figsize=(12, 6))\n",
    "plt.title('Total Occupancy per Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Occupancy')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./evolve_interview/naive_occupancy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./evolve_interview/naive_occupancy.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's do better\n",
    "\n",
    "This chart has some irregularities and is a little unclear about the type of trends we're looking for.\n",
    "\n",
    "Let's look at only the listings that are filled each day of the year, and look at their prices as the year goes by.\n",
    "\n",
    "We'll refer to these as \"indicator listings\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "days_filled = calendar_data.groupby('listing_id')[['filled']].sum()\n",
    "top_listings = days_filled[days_filled.filled == 365].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Datasize: 2872.\n",
      "Pruned Datasize: 81\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Datasize: {len(calendar_data.listing_id.unique())}.')\n",
    "print(f'Pruned Datasize: {len(top_listings)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shrinks our dataset by a lot, but that's ok.\n",
    "\n",
    "We're looking for indicator listings, not the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pruned_calendar_data = calendar_data[\n",
    "    calendar_data['listing_id'].isin(top_listings)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting our Busy Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for lid in top_listings:\n",
    "    cdata = pruned_calendar_data[pruned_calendar_data.listing_id == lid]\n",
    "    cdata = cdata.sort_values('date')\n",
    "    plt.plot(cdata.date, cdata.price)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Occupied Listing Price per Day')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./evolve_interview/all_filled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./evolve_interview/all_filled.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reducing Noise\n",
    "\n",
    "This chart has too much noise and the trends are even less clear.\n",
    "\n",
    "* Remove all listings with low standard deviation\n",
    "    * $10 < \\sigma < 200$\n",
    "* Also cut out all listings that only have a few unique values\n",
    "    * $\\left\\lvert \\left\\{ X \\right\\}\\right\\rvert > 10$\n",
    "* Periodicity is the enemy of seasonal trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "listing_price_deviations = pruned_calendar_data.groupby('listing_id')[['price']].std()\n",
    "listing_price_deviations.rename(columns={'price': 'stddev'}, inplace=True)\n",
    "listing_price_deviations = listing_price_deviations[\n",
    "    np.logical_and(\n",
    "        listing_price_deviations.stddev > 10,\n",
    "        listing_price_deviations.stddev < 200\n",
    "    )\n",
    "]\n",
    "listing_periodicity = pruned_calendar_data.groupby('listing_id')[['price']].nunique()\n",
    "listing_periodicity.rename(columns={'price': 'num_unique'}, inplace=True)\n",
    "listing_periodicity = listing_periodicity[\n",
    "    listing_periodicity.num_unique > 10\n",
    "]\n",
    "sensitive_listings = listing_price_deviations.join(listing_periodicity, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stddev</th>\n",
       "      <th>num_unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5455004</th>\n",
       "      <td>139.340961</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119918</th>\n",
       "      <td>128.657169</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827268</th>\n",
       "      <td>155.416406</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14421304</th>\n",
       "      <td>128.396181</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14421403</th>\n",
       "      <td>127.944730</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14421692</th>\n",
       "      <td>127.944730</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                stddev  num_unique\n",
       "listing_id                        \n",
       "5455004     139.340961         108\n",
       "6119918     128.657169         216\n",
       "8827268     155.416406         189\n",
       "14421304    128.396181          96\n",
       "14421403    127.944730         105\n",
       "14421692    127.944730         105"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitive_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sensitive_listings = sensitive_listings.index\n",
    "sensitive_calendar_data = calendar_data[calendar_data['listing_id'].isin(sensitive_listings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for lid in sensitive_listings:\n",
    "    cdata = sensitive_calendar_data[sensitive_calendar_data.listing_id == lid]\n",
    "    cdata = cdata.sort_values('date')\n",
    "    label = combined_data[combined_data.id == lid].name.values[0]\n",
    "    plt.plot(cdata.date, cdata.price, label=label)\n",
    "plt.legend(loc=0)\n",
    "plt.title('Indicator Listing Prices by Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./evolve_interview/indicators.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plotting our Indicator Listings\n",
    "\n",
    "<img src=\"./evolve_interview/indicators.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, axarr = plt.subplots(2, 1, figsize=(16, 12))\n",
    "for lid in sensitive_listings:\n",
    "    cdata = sensitive_calendar_data[sensitive_calendar_data.listing_id == lid]\n",
    "    cdata = cdata.sort_values('date')\n",
    "    label = combined_data[combined_data.id == lid].name.values[0]\n",
    "    axarr[0].plot(cdata.date.values, cdata.price.values, label=label)\n",
    "axarr[0].legend(loc=0)\n",
    "axarr[0].set_title('Indicator Listings')\n",
    "axarr[0].set_xlabel('Date')\n",
    "axarr[0].set_ylabel('Price')\n",
    "\n",
    "fill_dates = calendar_data.groupby('date')[['filled']].sum()\n",
    "axarr[1].plot(fill_dates.index.values, fill_dates.filled.values)\n",
    "axarr[1].set_title('Total Occupancy')\n",
    "axarr[1].set_xlabel('Date')\n",
    "axarr[1].set_ylabel('Occupancy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./evolve_interview/indicators_occupancy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining Naive Occupancy and Indicator Listings\n",
    "\n",
    "<img src=\"./evolve_interview/indicators_occupancy.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What does this tell us?\n",
    "\n",
    "* Winter was the busy season for 2016-2017\n",
    "    * Most likely because of family/holidays\n",
    "    * Also the cheapest\n",
    "* Summers are expensive\n",
    "* Memorial Day Weekend is expensive (the spike in the middle)\n",
    "    * [See this event guide for details](http://www.boston-discovery-guide.com/boston-event-calendar-may.html)\n",
    "* The start of MIT school year is expensive (spike at the right side)\n",
    "    * [See the academic calendar for more info](http://web.mit.edu/registrar/calendar/)\n",
    "* Visit Boston between New Years and March for the cheapest rates.\n",
    "* Weekends are more expensive than weekdays, but this doesn't influence occupancy.\n",
    "* Our naive approach looks weird in Fall 2016 due to AirBnB's increased activity in the area\n",
    "    * [See here for 2016 article](http://www.bostonherald.com/news/local_coverage/2016/10/airbnb_leaving_no_room_for_rentals)\n",
    "* [According](https://www.bostonglobe.com/business/2017/08/06/cambridge-set-vote-ordinance-regulate-airbnb/61Wc1phpViVbYv3x7ORMaI/story.html) to [a ton](https://www.bostonglobe.com/business/2017/10/05/housing-advocates-say-airbnb-rentals-are-replacing-chinatown-apartments/Z9KwIgppY89rHbbflvKC6H/story.html) of [news sources](http://www.wbur.org/bostonomix/2017/08/08/cambridge-short-term-rental-rules), this was an year of protest for AirBnB. This is probably skewing the data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These are good preliminary results, but for more accurate results we'd want several years to reduce influence of increased activity, year specific events, legal actions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neighborhood Specific Seasonal Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's dig into any seasonal trends we can find on a neighboorhood basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_combined_data = listing_data.merge(\n",
    "    calendar_data,\n",
    "    how='inner',\n",
    "    left_on='id',\n",
    "    right_on='listing_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot each neighborhood by their average price and fill-rate per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "full_combined_data = full_combined_data[~full_combined_data.available.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_data = full_combined_data\\\n",
    "    .groupby(['neighbourhood_cleansed', 'date'])\\\n",
    "    .agg({'filled': 'sum', 'price_y': 'mean'})\n",
    "neighborhood_data = neighborhood_data.unstack(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "neighborhood_data[['filled']].plot(\n",
    "    figsize=(12, 8),\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.ylabel('Occupancy')\n",
    "\n",
    "plt.title('Neighborhood Occupancy')\n",
    "plt.savefig('./evolve_interview/neighborhood_filled.png')\n",
    "\n",
    "neighborhood_data[['price_y']].plot(\n",
    "    figsize=(12, 8),\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.ylabel('Price')\n",
    "\n",
    "plt.title('Neighborhood Average Price')\n",
    "plt.savefig('./evolve_interview/neighborhood_price.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./evolve_interview/neighborhood_filled.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./evolve_interview/neighborhood_price.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What does this tell us?\n",
    "\n",
    "* As with before, Memorial Day Weekend stands out as a spike in pricing and a drop in occupancy\n",
    "* Weekends are more expensive\n",
    "* December and March 1st have a huge drop in occupancy and pricing\n",
    "* Not every seasonal trend affects every neighborhood! Some are immune (or do the opposite) of the average trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As with before, we'd ideally want more data to make more accurate observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examining Neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's also see if we can pull out neighbor features.\n",
    "\n",
    "Some listings don't have neighborhood descriptions, so let's skip those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "valid_desc_data = combined_data[combined_data.neighborhood_overview.notnull()].copy()\n",
    "neighborhood_labels = valid_desc_data.neighbourhood_cleansed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Roslindale', 'Jamaica Plain', 'Mission Hill',\n",
       "       'Longwood Medical Area', 'Bay Village', 'Leather District',\n",
       "       'Chinatown', 'North End', 'Roxbury', 'South End', 'Back Bay',\n",
       "       'East Boston', 'Charlestown', 'West End', 'Beacon Hill', 'Downtown',\n",
       "       'Fenway', 'Brighton', 'West Roxbury', 'Hyde Park', 'Mattapan',\n",
       "       'Dorchester', 'South Boston Waterfront', 'South Boston', 'Allston'], dtype=object)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhood_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How many listings per neighborhood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_cleansed\n",
       "Leather District             5\n",
       "Longwood Medical Area        6\n",
       "Mattapan                    14\n",
       "Hyde Park                   15\n",
       "Bay Village                 19\n",
       "West Roxbury                24\n",
       "West End                    32\n",
       "South Boston Waterfront     41\n",
       "Roslindale                  42\n",
       "Chinatown                   46\n",
       "Charlestown                 53\n",
       "Mission Hill                58\n",
       "East Boston                 87\n",
       "North End                   88\n",
       "Roxbury                     92\n",
       "Brighton                   105\n",
       "Downtown                   108\n",
       "South Boston               114\n",
       "Beacon Hill                131\n",
       "Dorchester                 144\n",
       "Allston                    146\n",
       "Fenway                     148\n",
       "Back Bay                   181\n",
       "South End                  225\n",
       "Jamaica Plain              246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_desc_data.groupby('neighbourhood_cleansed').agg('size').sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoe/.local/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "top5_neighborhoods = list(valid_desc_data.groupby('neighbourhood_cleansed').agg('size').sort_values().tail(5).index)\n",
    "top5_listings = valid_desc_data[valid_desc_data.neighbourhood_cleansed.isin(top5_neighborhoods)]\n",
    "for key, group in top5_listings.groupby('neighbourhood_cleansed'):\n",
    "    plt.figure()\n",
    "    text = '\\n'.join(group.neighborhood_overview.values)\n",
    "\n",
    "    wordcloud = WordCloud(width=1600, height=1200).generate(text)\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(key)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f'./evolve_interview/{\"_\".join(key.lower().split(\" \"))}_words.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Where are these neighborhoods?\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Boston_ONS_Neighborhoods.svg/1200px-Boston_ONS_Neighborhoods.svg.png\" style=\"width: 50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Top 5 Neighborhoods\n",
    "\n",
    "Let's only take the top 5 neighborhoods with the most listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Allston', 'Fenway', 'Back Bay', 'South End', 'Jamaica Plain']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a word cloud for each neighborhood based on the most common words in their descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Allston\n",
    "\n",
    "<img src=\"./evolve_interview/allston_words.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fenway\n",
    "\n",
    "<img src=\"./evolve_interview/fenway_words.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Back Bay\n",
    "\n",
    "<img src=\"./evolve_interview/back_bay_words.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## South End\n",
    "\n",
    "<img src=\"./evolve_interview/south_end_words.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Jamaica Plain\n",
    "\n",
    "<img src=\"./evolve_interview/jamaica_plain_words.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wordclouds are pretty, but also fairly crude. Let's take a deeper dive into these top 5 neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Jamaica Plain</td>\n",
       "      <td>The neighborhood is complete with all shops, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Jamaica Plain</td>\n",
       "      <td>Downtown Jamaica Plain is a delight with plent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Jamaica Plain</td>\n",
       "      <td>the neighborhood is exactly that ... a neighbo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbourhood_cleansed                              neighborhood_overview\n",
       "59          Jamaica Plain  The neighborhood is complete with all shops, r...\n",
       "60          Jamaica Plain  Downtown Jamaica Plain is a delight with plent...\n",
       "61          Jamaica Plain  the neighborhood is exactly that ... a neighbo..."
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_fulltext = top5_listings[['neighbourhood_cleansed',\n",
    "                               'neighborhood_overview']]\n",
    "top5_fulltext.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Term Frequency - Inverse Document Frequency\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf),\n",
    "\n",
    "> tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpu\n",
    "\n",
    "In essence, the product of \"how common a word is in the corpus\" and \"inverse of how frequently the term appears in the document set\".\n",
    "\n",
    "Using this concept we can construct a document matrix, where each row represents a document in the corpus, and each column represents a word that appeared.\n",
    "\n",
    "The big difference between this approach and our wordcloud approach from earlier which just relies on raw frequency is that this takes into account the overall frequency of the word in the entire document set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-Learn\n",
    "\n",
    "`sklearn` provides several vectorizers, including a tf-idf vectorizer.\n",
    "\n",
    "We give it a tokenizing regular expression in order to prune less relevant tokens (a token is just a unit of semantic meaning, in this case we only want words longer than 3 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "valid_word = '[A-Za-z_]'\n",
    "vect = TfidfVectorizer(\n",
    "    token_pattern=f'(?u)\\\\b{valid_word}{{5,}}\\\\b'\n",
    ")\n",
    "stemmer = porter2\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "top5_cleantext = np.empty(len(top5_fulltext), dtype=object)\n",
    "for i, text in enumerate(top5_fulltext.values[:, 1]):\n",
    "    splittext = [x for x in text.split(' ')\n",
    "                 if (len(x) > 3 and\n",
    "                     not x[0].isupper())]\n",
    "    top5_cleantext[i] = (' '.join(stemmer.stem(word) for word in tokenizer.tokenize(' '.join(splittext))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to feed this all of the listing descriptions from our top 5 neighborhoods and aggregate later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = vect.fit(top5_cleantext)\n",
    "X = vect.fit_transform(top5_cleantext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The shape of this document matrix, $946 \\times 1599$, indicates there are $946$ documents, and $1599$ tokens.\n",
    "\n",
    "This matrix is incredibly sparse however (only about 0.5% full), since not every token appears in every document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 1599)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0049293165834142748"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.astype(bool).sum() / (946 * 3019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using tf-idf\n",
    "\n",
    "Now that we have our document matrix, let's use it to figure out the most important words per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "neighborhood_docs = {i: name for i, name in enumerate(top5_fulltext.values[:, 0])}\n",
    "vocab = {v: k for k, v in fit.vocabulary_.items()}\n",
    "words = {x: [] for x in set(top5_fulltext.values[:, 0])}\n",
    "for (document, index), val in sc_sp.dok_matrix(X).items():\n",
    "    n = neighborhood_docs[document]\n",
    "    word = vocab[index]\n",
    "    heapq.heappush(words[n], (val, word))\n",
    "summary = ''\n",
    "for neighborhood, wordlist in words.items():\n",
    "    wordlist = wordlist[::-1]\n",
    "    final_list = []\n",
    "    for val, word in wordlist:\n",
    "        if len(final_list) > 15:\n",
    "            break\n",
    "        if word not in final_list:\n",
    "            final_list.append(word)\n",
    "    summary += (f'{neighborhood}:\\n\\t{\", \".join(final_list)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South End:\n",
      "\tdistanc, yourself, brownston, locat, young, across, years, wrought, would, worlds, world, wonder, discov, within, dinner, beauti\n",
      "\n",
      "Fenway:\n",
      "\tdynam, young, museum, attract, years, would, worth, worri, wonder, anyth, women, without, within, multicultur, moist, modern\n",
      "\n",
      "Back Bay:\n",
      "\thospit, years, convention, wrong, convent, worth, appreci, homes, block, histori, wonder, histor, within, conveni, almost, window\n",
      "\n",
      "Jamaica Plain:\n",
      "\tzagat, yummi, lucki, youth, yourself, younger, distanc, young, along, longer, locations, burger, locat, would, worth, worst\n",
      "\n",
      "Allston:\n",
      "\tminut, youth, decid, younger, blocks, culture, young, block, anywher, activ, cultur, biking, between, midst, world, midnight\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What does this tell us?\n",
    "\n",
    "* Stemming (converting words to their \"base\" form) is tricky, and innacurate\n",
    "* Tf-Idf emphasizes words that appear in fewer documents\n",
    "    * This gives us a better summary instead of just seeing \"Boston\" for every neighborhood\n",
    "* The advantage this provides over just word frequencies is that we see the important things that aren't mentioned frequently.\n",
    "* South End:\n",
    "\t* Located in a good spot, younger crowd, good restaurants, \"deeper beauty\".\n",
    "* Fenway\n",
    "\t* Younger crowd, has museums, multicultural, modern.\n",
    "* Back Bay:\n",
    "\t* Hospital access, conventions here, high value, historical districts\n",
    "* Jamaica Plain:\n",
    "\t* Lots of zagat-reviewed restaurants, good food here, younger crowd.\n",
    "* Allston:\n",
    "\t* Younger crowd, access to outdoors activities (biking, etc.), active nightlife."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Seasonal Trends\n",
    "\n",
    "<img src=\"./evolve_interview/indicators_occupancy.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Winter was the busy season for 2016-2017\n",
    "    * Most likely because of family/holidays\n",
    "    * Also the cheapest\n",
    "* Summers are expensive\n",
    "* Memorial Day Weekend is expensive (the spike in the middle)\n",
    "    * [See this event guide for details](http://www.boston-discovery-guide.com/boston-event-calendar-may.html)\n",
    "* The start of MIT school year is expensive (spike at the right side)\n",
    "    * [See the academic calendar for more info](http://web.mit.edu/registrar/calendar/)\n",
    "* Visit Boston between New Years and March for the cheapest rates.\n",
    "* Weekends are more expensive than weekdays, but this doesn't influence occupancy.\n",
    "* Our naive approach looks weird in Fall 2016 due to AirBnB's increased activity in the area\n",
    "    * [See here for 2016 article](http://www.bostonherald.com/news/local_coverage/2016/10/airbnb_leaving_no_room_for_rentals)\n",
    "* [According](https://www.bostonglobe.com/business/2017/08/06/cambridge-set-vote-ordinance-regulate-airbnb/61Wc1phpViVbYv3x7ORMaI/story.html) to [a ton](https://www.bostonglobe.com/business/2017/10/05/housing-advocates-say-airbnb-rentals-are-replacing-chinatown-apartments/Z9KwIgppY89rHbbflvKC6H/story.html) of [news sources](http://www.wbur.org/bostonomix/2017/08/08/cambridge-short-term-rental-rules), this was an year of protest for AirBnB. This is probably skewing the data\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./evolve_interview/neighborhood_filled.png\" style=\"display: inline-block; width: 50%; height: 50%\" />\n",
    "<img src=\"./evolve_interview/neighborhood_price.png\" style=\"display: inline-block; width: 49%; height: 49%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* As with before, Memorial Day Weekend stands out as a spike in pricing and a drop in occupancy\n",
    "* Weekends are more expensive\n",
    "* December and March 1st have a huge drop in occupancy and pricing\n",
    "* Not every seasonal trend affects every neighborhood! Some are immune (or do the opposite) of the average trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Leather District, West End, and Chinatown are the most expensive places to live.\n",
    "\n",
    "<img src=\"./evolve_interview/neighborhood_stats.png\" style=\"width: 100%; height: 50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./evolve_interview/allston_words.png\" style=\"display: inline-block; width: 30%\" />\n",
    "<img src=\"./evolve_interview/fenway_words.png\" style=\"display: inline-block; width: 30%\" />\n",
    "<img src=\"./evolve_interview/back_bay_words.png\" style=\"display: inline-block; width: 30%\" />\n",
    "<img src=\"./evolve_interview/south_end_words.png\" style=\"display: inline-block; width: 30%\" />\n",
    "<img src=\"./evolve_interview/jamaica_plain_words.png\" style=\"display: inline-block; width: 30%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* South End:\n",
    "\t* Located in a good spot, younger crowd, good restaurants, \"deeper beauty\".\n",
    "* Fenway\n",
    "\t* Younger crowd, has museums, multicultural, modern.\n",
    "* Back Bay:\n",
    "\t* Hospital access, conventions here, high value, historical districts\n",
    "* Jamaica Plain:\n",
    "\t* Lots of zagat-reviewed restaurants, good food here, younger crowd.\n",
    "* Allston:\n",
    "\t* Younger crowd, access to outdoors activities (biking, etc.), active nightlife."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?\n",
    "\n",
    "* [zoe@dataleek.io](mailto:zoe@dataleek.io)\n",
    "* [https://gitlab.com/thedataleek/evolve_interview](https://gitlab.com/thedataleek/evolve_interview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
